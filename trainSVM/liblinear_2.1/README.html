<!DOCTYPE html><html><head><meta charset="utf-8"><style>body {
  width: 45em;
  border: 1px solid #ddd;
  outline: 1300px solid #fff;
  margin: 16px auto;
}

body .markdown-body
{
  padding: 30px;
}

@font-face {
  font-family: fontawesome-mini;
  src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
}

@font-face {
  font-family: octicons-anchor;
  src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
}

.markdown-body {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
  color: #333333;
  overflow: hidden;
  font-family: "Helvetica Neue", Helvetica, "Segoe UI", Arial, freesans, sans-serif;
  font-size: 16px;
  line-height: 1.6;
  word-wrap: break-word;
}

.markdown-body a {
  background: transparent;
}

.markdown-body a:active,
.markdown-body a:hover {
  outline: 0;
}

.markdown-body b,
.markdown-body strong {
  font-weight: bold;
}

.markdown-body mark {
  background: #ff0;
  color: #000;
  font-style: italic;
  font-weight: bold;
}

.markdown-body sub,
.markdown-body sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
.markdown-body sup {
  top: -0.5em;
}
.markdown-body sub {
  bottom: -0.25em;
}

.markdown-body h1 {
  font-size: 2em;
  margin: 0.67em 0;
}

.markdown-body img {
  border: 0;
}

.markdown-body hr {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
  height: 0;
}

.markdown-body pre {
  overflow: auto;
}

.markdown-body code,
.markdown-body kbd,
.markdown-body pre,
.markdown-body samp {
  font-family: monospace, monospace;
  font-size: 1em;
}

.markdown-body input {
  color: inherit;
  font: inherit;
  margin: 0;
}

.markdown-body html input[disabled] {
  cursor: default;
}

.markdown-body input {
  line-height: normal;
}

.markdown-body input[type="checkbox"] {
  box-sizing: border-box;
  padding: 0;
}

.markdown-body table {
  border-collapse: collapse;
  border-spacing: 0;
}

.markdown-body td,
.markdown-body th {
  padding: 0;
}

.markdown-body .codehilitetable {
  border: 0;
  border-spacing: 0;
}

.markdown-body .codehilitetable tr {
  border: 0;
}

.markdown-body .codehilitetable pre,
.markdown-body .codehilitetable div.codehilite {
  margin: 0;
}

.markdown-body .linenos,
.markdown-body .code,
.markdown-body .codehilitetable td {
  border: 0;
  padding: 0;
}

.markdown-body td:not(.linenos) .linenodiv {
  padding: 0 !important;
}

.markdown-body .code {
  width: 100%;
}

.markdown-body .linenos div pre,
.markdown-body .linenodiv pre,
.markdown-body .linenodiv {
  border: 0;
  -webkit-border-radius: 0;
  -moz-border-radius: 0;
  border-radius: 0;
  -webkit-border-top-left-radius: 3px;
  -webkit-border-bottom-left-radius: 3px;
  -moz-border-radius-topleft: 3px;
  -moz-border-radius-bottomleft: 3px;
  border-top-left-radius: 3px;
  border-bottom-left-radius: 3px;
}

.markdown-body .code div pre,
.markdown-body .code div {
  border: 0;
  -webkit-border-radius: 0;
  -moz-border-radius: 0;
  border-radius: 0;
  -webkit-border-top-right-radius: 3px;
  -webkit-border-bottom-right-radius: 3px;
  -moz-border-radius-topright: 3px;
  -moz-border-radius-bottomright: 3px;
  border-top-right-radius: 3px;
  border-bottom-right-radius: 3px;
}

.markdown-body * {
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}

.markdown-body input {
  font: 13px Helvetica, arial, freesans, clean, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol";
  line-height: 1.4;
}

.markdown-body a {
  color: #4183c4;
  text-decoration: none;
}

.markdown-body a:hover,
.markdown-body a:focus,
.markdown-body a:active {
  text-decoration: underline;
}

.markdown-body hr {
  height: 0;
  margin: 15px 0;
  overflow: hidden;
  background: transparent;
  border: 0;
  border-bottom: 1px solid #ddd;
}

.markdown-body hr:before,
.markdown-body hr:after {
  display: table;
  content: " ";
}

.markdown-body hr:after {
  clear: both;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  margin-top: 15px;
  margin-bottom: 15px;
  line-height: 1.1;
}

.markdown-body h1 {
  font-size: 30px;
}

.markdown-body h2 {
  font-size: 21px;
}

.markdown-body h3 {
  font-size: 16px;
}

.markdown-body h4 {
  font-size: 14px;
}

.markdown-body h5 {
  font-size: 12px;
}

.markdown-body h6 {
  font-size: 11px;
}

.markdown-body blockquote {
  margin: 0;
}

.markdown-body ul,
.markdown-body ol {
  padding: 0;
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body ol ol,
.markdown-body ul ol {
  list-style-type: lower-roman;
}

.markdown-body ul ul ol,
.markdown-body ul ol ol,
.markdown-body ol ul ol,
.markdown-body ol ol ol {
  list-style-type: lower-alpha;
}

.markdown-body dd {
  margin-left: 0;
}

.markdown-body code,
.markdown-body pre,
.markdown-body samp {
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  font-size: 12px;
}

.markdown-body pre {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body kbd {
  background-color: #e7e7e7;
  background-image: -moz-linear-gradient(#fefefe, #e7e7e7);
  background-image: -webkit-linear-gradient(#fefefe, #e7e7e7);
  background-image: linear-gradient(#fefefe, #e7e7e7);
  background-repeat: repeat-x;
  border-radius: 2px;
  border: 1px solid #cfcfcf;
  color: #000;
  padding: 3px 5px;
  line-height: 10px;
  font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
  display: inline-block;
}

.markdown-body>*:first-child {
  margin-top: 0 !important;
}

.markdown-body>*:last-child {
  margin-bottom: 0 !important;
}

.markdown-body .headeranchor-link {
  position: absolute;
  top: 0;
  bottom: 0;
  left: 0;
  display: block;
  padding-right: 6px;
  padding-left: 30px;
  margin-left: -30px;
}

.markdown-body .headeranchor-link:focus {
  outline: none;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  position: relative;
  margin-top: 1em;
  margin-bottom: 16px;
  font-weight: bold;
  line-height: 1.4;
}

.markdown-body h1 .headeranchor,
.markdown-body h2 .headeranchor,
.markdown-body h3 .headeranchor,
.markdown-body h4 .headeranchor,
.markdown-body h5 .headeranchor,
.markdown-body h6 .headeranchor {
  display: none;
  color: #000;
  vertical-align: middle;
}

.markdown-body h1:hover .headeranchor-link,
.markdown-body h2:hover .headeranchor-link,
.markdown-body h3:hover .headeranchor-link,
.markdown-body h4:hover .headeranchor-link,
.markdown-body h5:hover .headeranchor-link,
.markdown-body h6:hover .headeranchor-link {
  height: 1em;
  padding-left: 8px;
  margin-left: -30px;
  line-height: 1;
  text-decoration: none;
}

.markdown-body h1:hover .headeranchor-link .headeranchor,
.markdown-body h2:hover .headeranchor-link .headeranchor,
.markdown-body h3:hover .headeranchor-link .headeranchor,
.markdown-body h4:hover .headeranchor-link .headeranchor,
.markdown-body h5:hover .headeranchor-link .headeranchor,
.markdown-body h6:hover .headeranchor-link .headeranchor {
  display: inline-block;
}

.markdown-body h1 {
  padding-bottom: 0.3em;
  font-size: 2.25em;
  line-height: 1.2;
  border-bottom: 1px solid #eee;
}

.markdown-body h2 {
  padding-bottom: 0.3em;
  font-size: 1.75em;
  line-height: 1.225;
  border-bottom: 1px solid #eee;
}

.markdown-body h3 {
  font-size: 1.5em;
  line-height: 1.43;
}

.markdown-body h4 {
  font-size: 1.25em;
}

.markdown-body h5 {
  font-size: 1em;
}

.markdown-body h6 {
  font-size: 1em;
  color: #777;
}

.markdown-body p,
.markdown-body blockquote,
.markdown-body ul,
.markdown-body ol,
.markdown-body dl,
.markdown-body table,
.markdown-body pre,
.markdown-body .admonition {
  margin-top: 0;
  margin-bottom: 16px;
}

.markdown-body hr {
  height: 4px;
  padding: 0;
  margin: 16px 0;
  background-color: #e7e7e7;
  border: 0 none;
}

.markdown-body ul,
.markdown-body ol {
  padding-left: 2em;
}

.markdown-body ul ul,
.markdown-body ul ol,
.markdown-body ol ol,
.markdown-body ol ul {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body li>p {
  margin-top: 16px;
}

.markdown-body dl {
  padding: 0;
}

.markdown-body dl dt {
  padding: 0;
  margin-top: 16px;
  font-size: 1em;
  font-style: italic;
  font-weight: bold;
}

.markdown-body dl dd {
  padding: 0 16px;
  margin-bottom: 16px;
}

.markdown-body blockquote {
  padding: 0 15px;
  color: #777;
  border-left: 4px solid #ddd;
}

.markdown-body blockquote>:first-child {
  margin-top: 0;
}

.markdown-body blockquote>:last-child {
  margin-bottom: 0;
}

.markdown-body table {
  display: block;
  width: 100%;
  overflow: auto;
  word-break: normal;
  word-break: keep-all;
}

.markdown-body table th {
  font-weight: bold;
}

.markdown-body table th,
.markdown-body table td {
  padding: 6px 13px;
  border: 1px solid #ddd;
}

.markdown-body table tr {
  background-color: #fff;
  border-top: 1px solid #ccc;
}

.markdown-body table tr:nth-child(2n) {
  background-color: #f8f8f8;
}

.markdown-body img {
  max-width: 100%;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}

.markdown-body code,
.markdown-body samp {
  padding: 0;
  padding-top: 0.2em;
  padding-bottom: 0.2em;
  margin: 0;
  font-size: 85%;
  background-color: rgba(0,0,0,0.04);
  border-radius: 3px;
}

.markdown-body code:before,
.markdown-body code:after {
  letter-spacing: -0.2em;
  content: "\00a0";
}

.markdown-body pre>code {
  padding: 0;
  margin: 0;
  font-size: 100%;
  word-break: normal;
  white-space: pre;
  background: transparent;
  border: 0;
}

.markdown-body .codehilite {
  margin-bottom: 16px;
}

.markdown-body .codehilite pre,
.markdown-body pre {
  padding: 16px;
  overflow: auto;
  font-size: 85%;
  line-height: 1.45;
  background-color: #f7f7f7;
  border-radius: 3px;
}

.markdown-body .codehilite pre {
  margin-bottom: 0;
  word-break: normal;
}

.markdown-body pre {
  word-wrap: normal;
}

.markdown-body pre code {
  display: inline;
  max-width: initial;
  padding: 0;
  margin: 0;
  overflow: initial;
  line-height: inherit;
  word-wrap: normal;
  background-color: transparent;
  border: 0;
}

.markdown-body pre code:before,
.markdown-body pre code:after {
  content: normal;
}

/* Admonition */
.markdown-body .admonition {
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  position: relative;
  border-radius: 3px;
  border: 1px solid #e0e0e0;
  border-left: 6px solid #333;
  padding: 10px 10px 10px 30px;
}

.markdown-body .admonition table {
  color: #333;
}

.markdown-body .admonition p {
  padding: 0;
}

.markdown-body .admonition-title {
  font-weight: bold;
  margin: 0;
}

.markdown-body .admonition>.admonition-title {
  color: #333;
}

.markdown-body .attention>.admonition-title {
  color: #a6d796;
}

.markdown-body .caution>.admonition-title {
  color: #d7a796;
}

.markdown-body .hint>.admonition-title {
  color: #96c6d7;
}

.markdown-body .danger>.admonition-title {
  color: #c25f77;
}

.markdown-body .question>.admonition-title {
  color: #96a6d7;
}

.markdown-body .note>.admonition-title {
  color: #d7c896;
}

.markdown-body .admonition:before,
.markdown-body .attention:before,
.markdown-body .caution:before,
.markdown-body .hint:before,
.markdown-body .danger:before,
.markdown-body .question:before,
.markdown-body .note:before {
  font: normal normal 16px fontawesome-mini;
  -moz-osx-font-smoothing: grayscale;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  line-height: 1.5;
  color: #333;
  position: absolute;
  left: 0;
  top: 0;
  padding-top: 10px;
  padding-left: 10px;
}

.markdown-body .admonition:before {
  content: "\f056\00a0";
  color: 333;
}

.markdown-body .attention:before {
  content: "\f058\00a0";
  color: #a6d796;
}

.markdown-body .caution:before {
  content: "\f06a\00a0";
  color: #d7a796;
}

.markdown-body .hint:before {
  content: "\f05a\00a0";
  color: #96c6d7;
}

.markdown-body .danger:before {
  content: "\f057\00a0";
  color: #c25f77;
}

.markdown-body .question:before {
  content: "\f059\00a0";
  color: #96a6d7;
}

.markdown-body .note:before {
  content: "\f040\00a0";
  color: #d7c896;
}

.markdown-body .admonition::after {
  content: normal;
}

.markdown-body .attention {
  border-left: 6px solid #a6d796;
}

.markdown-body .caution {
  border-left: 6px solid #d7a796;
}

.markdown-body .hint {
  border-left: 6px solid #96c6d7;
}

.markdown-body .danger {
  border-left: 6px solid #c25f77;
}

.markdown-body .question {
  border-left: 6px solid #96a6d7;
}

.markdown-body .note {
  border-left: 6px solid #d7c896;
}

.markdown-body .admonition>*:first-child {
  margin-top: 0 !important;
}

.markdown-body .admonition>*:last-child {
  margin-bottom: 0 !important;
}

/* progress bar*/
.markdown-body .progress {
  display: block;
  width: 300px;
  margin: 10px 0;
  height: 24px;
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  border-radius: 3px;
  background-color: #ededed;
  position: relative;
  box-shadow: inset -1px 1px 3px rgba(0, 0, 0, .1);
}

.markdown-body .progress-label {
  position: absolute;
  text-align: center;
  font-weight: bold;
  width: 100%; margin: 0;
  line-height: 24px;
  color: #333;
  text-shadow: 1px 1px 0 #fefefe, -1px -1px 0 #fefefe, -1px 1px 0 #fefefe, 1px -1px 0 #fefefe, 0 1px 0 #fefefe, 0 -1px 0 #fefefe, 1px 0 0 #fefefe, -1px 0 0 #fefefe, 1px 1px 2px #000;
  -webkit-font-smoothing: antialiased !important;
  white-space: nowrap;
  overflow: hidden;
}

.markdown-body .progress-bar {
  height: 24px;
  float: left;
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  border-radius: 3px;
  background-color: #96c6d7;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, .5), inset 0 -1px 0 rgba(0, 0, 0, .1);
  background-size: 30px 30px;
  background-image: -webkit-linear-gradient(
    135deg, rgba(255, 255, 255, .4) 27%,
    transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%,
    transparent 77%, transparent
  );
  background-image: -moz-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: -ms-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: -o-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
}

.markdown-body .progress-100plus .progress-bar {
  background-color: #a6d796;
}

.markdown-body .progress-80plus .progress-bar {
  background-color: #c6d796;
}

.markdown-body .progress-60plus .progress-bar {
  background-color: #d7c896;
}

.markdown-body .progress-40plus .progress-bar {
  background-color: #d7a796;
}

.markdown-body .progress-20plus .progress-bar {
  background-color: #d796a6;
}

.markdown-body .progress-0plus .progress-bar {
  background-color: #c25f77;
}

.markdown-body .candystripe-animate .progress-bar{
  -webkit-animation: animate-stripes 3s linear infinite;
  -moz-animation: animate-stripes 3s linear infinite;
  animation: animate-stripes 3s linear infinite;
}

@-webkit-keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

@-moz-keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

@keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

.markdown-body .gloss .progress-bar {
  box-shadow:
    inset 0 4px 12px rgba(255, 255, 255, .7),
    inset 0 -12px 0 rgba(0, 0, 0, .05);
}

/* Multimarkdown Critic Blocks */
.markdown-body .critic_mark {
  background: #ff0;
}

.markdown-body .critic_delete {
  color: #c82829;
  text-decoration: line-through;
}

.markdown-body .critic_insert {
  color: #718c00 ;
  text-decoration: underline;
}

.markdown-body .critic_comment {
  color: #8e908c;
  font-style: italic;
}

.markdown-body .headeranchor {
  font: normal normal 16px octicons-anchor;
  line-height: 1;
  display: inline-block;
  text-decoration: none;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.headeranchor:before {
  content: '\f05c';
}

.markdown-body .task-list-item {
  list-style-type: none;
}

.markdown-body .task-list-item+.task-list-item {
  margin-top: 3px;
}

.markdown-body .task-list-item input {
  margin: 0 4px 0.25em -20px;
  vertical-align: middle;
}

/* Media */
@media only screen and (min-width: 480px) {
  .markdown-body {
    font-size:14px;
  }
}

@media only screen and (min-width: 768px) {
  .markdown-body {
    font-size:16px;
  }
}

@media print {
  .markdown-body * {
    background: transparent !important;
    color: black !important;
    filter:none !important;
    -ms-filter: none !important;
  }

  .markdown-body {
    font-size:12pt;
    max-width:100%;
    outline:none;
    border: 0;
  }

  .markdown-body a,
  .markdown-body a:visited {
    text-decoration: underline;
  }

  .markdown-body .headeranchor-link {
    display: none;
  }

  .markdown-body a[href]:after {
    content: " (" attr(href) ")";
  }

  .markdown-body abbr[title]:after {
    content: " (" attr(title) ")";
  }

  .markdown-body .ir a:after,
  .markdown-body a[href^="javascript:"]:after,
  .markdown-body a[href^="#"]:after {
    content: "";
  }

  .markdown-body pre {
    white-space: pre;
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .markdown-body pre,
  .markdown-body blockquote {
    border: 1px solid #999;
    padding-right: 1em;
    page-break-inside: avoid;
  }

  .markdown-body .progress,
  .markdown-body .progress-bar {
    -moz-box-shadow: none;
    -webkit-box-shadow: none;
    box-shadow: none;
  }

  .markdown-body .progress {
    border: 1px solid #ddd;
  }

  .markdown-body .progress-bar {
    height: 22px;
    border-right: 1px solid #ddd;
  }

  .markdown-body tr,
  .markdown-body img {
    page-break-inside: avoid;
  }

  .markdown-body img {
    max-width: 100% !important;
  }

  .markdown-body p,
  .markdown-body h2,
  .markdown-body h3 {
    orphans: 3;
    widows: 3;
  }

  .markdown-body h2,
  .markdown-body h3 {
    page-break-after: avoid;
  }
}
</style><title>README</title></head><body><article class="markdown-body"><p>LIBLINEAR is a simple package for solving large-scale regularized linear <br />
classification and regression. It currently supports <br />
- L2-regularized logistic regression/L2-loss support vector classification/L1-loss support vector classification<br />
- L1-regularized L2-loss support vector classification/L1-regularized logistic regression<br />
- L2-regularized L2-loss support vector regression/L1-loss support vector regression. <br />
This document explains the usage of LIBLINEAR.</p>
<p>To get started, please read the <code>Quick Start</code> section first.<br />
For developers, please check the <code>Library Usage</code> section to learn<br />
how to integrate LIBLINEAR in your software.</p>
<h1 id="table-of-contents"><a name="user-content-table-of-contents" href="#table-of-contents" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Table of Contents</h1>
<ul>
<li>When to use LIBLINEAR but not LIBSVM</li>
<li>Quick Start</li>
<li>Installation</li>
<li><code>train</code> Usage</li>
<li><code>predict</code> Usage</li>
<li>Examples</li>
<li>Library Usage</li>
<li>Building Windows Binaries</li>
<li>Additional Information</li>
<li>MATLAB/OCTAVE interface</li>
<li>PYTHON interface</li>
</ul>
<h1 id="when-to-use-liblinear-but-not-libsvm"><a name="user-content-when-to-use-liblinear-but-not-libsvm" href="#when-to-use-liblinear-but-not-libsvm" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>When to use LIBLINEAR but not LIBSVM</h1>
<p>There are some large data for which with/without nonlinear mappings<br />
gives similar performances.  Without using kernels, one can<br />
efficiently train a much larger set via linear classification/regression.<br />
These data usually have a large number of features. Document classification<br />
is an example.</p>
<p>Warning: While generally liblinear is very fast, its default solver<br />
may be slow under certain situations (e.g., data not scaled or C is<br />
large). See Appendix B of our SVM guide about how to handle such<br />
cases.<br />
<a href="http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf">http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf</a></p>
<p>Warning: If you are a beginner and your data sets are not large, you<br />
should consider LIBSVM first.</p>
<p>LIBSVM page:<br />
<a href="http://www.csie.ntu.edu.tw/~cjlin/libsvm">http://www.csie.ntu.edu.tw/~cjlin/libsvm</a></p>
<h1 id="quick-start"><a name="user-content-quick-start" href="#quick-start" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Quick Start</h1>
<p>See the section <code>Installation</code> for installing LIBLINEAR.</p>
<p>After installation, there are programs <code>train</code> and <code>predict</code> for<br />
training and testing, respectively.</p>
<p>About the data format, please check the README file of LIBSVM. Note<br />
that feature index must start from 1 (but not 0).</p>
<p>A sample classification data included in this package is <code>heart_scale</code>.</p>
<p>Type <code>train heart_scale</code>, and the program will read the training<br />
data and output the model file <code>heart_scale.model</code>. If you have a test<br />
set called heart_scale.t, then type <code>predict heart_scale.t
heart_scale.model output</code> to see the prediction accuracy. The <code>output</code><br />
file contains the predicted class labels.</p>
<p>For more information about <code>train</code> and <code>predict</code>, see the sections<br />
<code>train</code> Usage and <code>predict</code> Usage.</p>
<p>To obtain good performances, sometimes one needs to scale the<br />
data. Please check the program <code>svm-scale</code> of LIBSVM. For large and<br />
sparse data, use <code>-l 0</code> to keep the sparsity.</p>
<h1 id="installation"><a name="user-content-installation" href="#installation" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Installation</h1>
<p>On Unix systems, type <code>make</code> to build the <code>train</code> and <code>predict</code><br />
programs. Run them without arguments to show the usages.</p>
<p>On other systems, consult <code>Makefile</code> to build them (e.g., see<br />
<code>Building Windows binaries</code> in this file) or use the pre-built<br />
binaries (Windows binaries are in the directory <code>windows</code>).</p>
<p>This software uses some level-1 BLAS subroutines. The needed functions are<br />
included in this package.  If a BLAS library is available on your<br />
machine, you may use it by modifying the Makefile: Unmark the following line</p>
<pre><code>    #LIBS ?= -lblas
</code></pre>
<p>and mark</p>
<pre><code>    LIBS ?= blas/blas.a
</code></pre>
<h1 id="train-usage"><code>train</code> Usage</h1>
<p>Usage: train [options] training_set_file [model_file]<br />
options:<br />
-s type : set type of solver (default 1)<br />
  for multi-class classification<br />
     0 &ndash; L2-regularized logistic regression (primal)<br />
     1 &ndash; L2-regularized L2-loss support vector classification (dual)<br />
     2 &ndash; L2-regularized L2-loss support vector classification (primal)<br />
     3 &ndash; L2-regularized L1-loss support vector classification (dual)<br />
     4 &ndash; support vector classification by Crammer and Singer<br />
     5 &ndash; L1-regularized L2-loss support vector classification<br />
     6 &ndash; L1-regularized logistic regression<br />
     7 &ndash; L2-regularized logistic regression (dual)<br />
  for regression<br />
    11 &ndash; L2-regularized L2-loss support vector regression (primal)<br />
    12 &ndash; L2-regularized L2-loss support vector regression (dual)<br />
    13 &ndash; L2-regularized L1-loss support vector regression (dual)<br />
-c cost : set the parameter C (default 1)<br />
-p epsilon : set the epsilon in loss function of epsilon-SVR (default 0.1)<br />
-e epsilon : set tolerance of termination criterion<br />
    -s 0 and 2<br />
        |f<code>(w)|_2 &lt;= eps*min(pos,neg)/l*|f</code>(w0)|_2,<br />
        where f is the primal function and pos/neg are # of<br />
        positive/negative data (default 0.01)<br />
    -s 11<br />
        |f<code>(w)|_2 &lt;= eps*|f</code>(w0)|_2 (default 0.001) <br />
    -s 1, 3, 4 and 7<br />
        Dual maximal violation &lt;= eps; similar to libsvm (default 0.1)<br />
    -s 5 and 6<br />
        |f<code>(w)|_1 &lt;= eps*min(pos,neg)/l*|f</code>(w0)|_1,<br />
        where f is the primal function (default 0.01)<br />
    -s 12 and 13\n&rdquo;<br />
        |f<code>(alpha)|_1 &lt;= eps |f</code>(alpha0)|,<br />
        where f is the dual function (default 0.1)<br />
-B bias : if bias &gt;= 0, instance x becomes [x; bias]; if &lt; 0, no bias term added (default -1)<br />
-wi weight: weights adjust the parameter C of different classes (see README for details)<br />
-v n: n-fold cross validation mode<br />
-C : find parameter C (only for -s 0 and 2)<br />
-q : quiet mode (no outputs)</p>
<p>Option -v randomly splits the data into n parts and calculates cross<br />
validation accuracy on them.</p>
<p>Option -C conducts cross validation under different C values and finds<br />
the best one. This options is supported only by -s 0 and -s 2. If<br />
the solver is not specified, -s 2 is used.</p>
<p>Formulations:</p>
<p>For L2-regularized logistic regression (-s 0), we solve</p>
<p>min_w w^Tw/2 + C \sum log(1 + exp(-y_i w^Tx_i))</p>
<p>For L2-regularized L2-loss SVC dual (-s 1), we solve</p>
<p>min_alpha  0.5(alpha^T (Q + I/2/C) alpha) - e^T alpha<br />
    s.t.   0 &lt;= alpha_i,</p>
<p>For L2-regularized L2-loss SVC (-s 2), we solve</p>
<p>min_w w^Tw/2 + C \sum max(0, 1- y_i w^Tx_i)^2</p>
<p>For L2-regularized L1-loss SVC dual (-s 3), we solve</p>
<p>min_alpha  0.5(alpha^T Q alpha) - e^T alpha<br />
    s.t.   0 &lt;= alpha_i &lt;= C,</p>
<p>For L1-regularized L2-loss SVC (-s 5), we solve</p>
<p>min_w \sum |w_j| + C \sum max(0, 1- y_i w^Tx_i)^2</p>
<p>For L1-regularized logistic regression (-s 6), we solve</p>
<p>min_w \sum |w_j| + C \sum log(1 + exp(-y_i w^Tx_i))</p>
<p>For L2-regularized logistic regression (-s 7), we solve</p>
<p>min_alpha  0.5(alpha^T Q alpha) + \sum alpha_i<em>log(alpha_i) + \sum (C-alpha_i)</em>log(C-alpha_i) - a constant<br />
    s.t.   0 &lt;= alpha_i &lt;= C,</p>
<p>where</p>
<p>Q is a matrix with Q_ij = y_i y_j x_i^T x_j.</p>
<p>For L2-regularized L2-loss SVR (-s 11), we solve</p>
<p>min_w w^Tw/2 + C \sum max(0, |y_i-w^Tx_i|-epsilon)^2</p>
<p>For L2-regularized L2-loss SVR dual (-s 12), we solve</p>
<p>min_beta  0.5(beta^T (Q + lambda I/2/C) beta) - y^T beta + \sum |beta_i|</p>
<p>For L2-regularized L1-loss SVR dual (-s 13), we solve</p>
<p>min_beta  0.5(beta^T Q beta) - y^T beta + \sum |beta_i|<br />
    s.t.   -C &lt;= beta_i &lt;= C,</p>
<p>where</p>
<p>Q is a matrix with Q_ij = x_i^T x_j.</p>
<p>If bias &gt;= 0, w becomes [w; w_{n+1}] and x becomes [x; bias].</p>
<p>The primal-dual relationship implies that -s 1 and -s 2 give the same<br />
model, -s 0 and -s 7 give the same, and -s 11 and -s 12 give the same.</p>
<p>We implement 1-vs-the rest multi-class strategy for classification. <br />
In training i vs. non_i, their C parameters are (weight from -wi)<em>C <br />
and C, respectively. If there are only two classes, we train only one<br />
model. Thus weight1</em>C vs. weight2*C is used. See examples below.</p>
<p>We also implement multi-class SVM by Crammer and Singer (-s 4):</p>
<p>min_{w_m, \xi_i}  0.5 \sum_m ||w_m||^2 + C \sum_i \xi_i<br />
    s.t.  w^T_{y_i} x_i - w^T_m x_i &gt;= \e^m_i - \xi_i \forall m,i</p>
<p>where e^m_i = 0 if y_i  = m,<br />
      e^m_i = 1 if y_i != m,</p>
<p>Here we solve the dual problem:</p>
<p>min_{\alpha}  0.5 \sum_m ||w_m(\alpha)||^2 + \sum_i \sum_m e^m_i alpha^m_i<br />
    s.t.  \alpha^m_i &lt;= C^m_i \forall m,i , \sum_m \alpha^m_i=0 \forall i</p>
<p>where w_m(\alpha) = \sum_i \alpha^m_i x_i,<br />
and C^m_i = C if m  = y_i,<br />
    C^m_i = 0 if m != y_i.</p>
<h1 id="predict-usage"><code>predict</code> Usage</h1>
<p>Usage: predict [options] test_file model_file output_file<br />
options:<br />
-b probability_estimates: whether to output probability estimates, 0 or 1 (default 0); currently for logistic regression only<br />
-q : quiet mode (no outputs)</p>
<p>Note that -b is only needed in the prediction phase. This is different<br />
from the setting of LIBSVM.</p>
<h1 id="examples"><a name="user-content-examples" href="#examples" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Examples</h1>
<blockquote>
<p>train data_file</p>
</blockquote>
<p>Train linear SVM with L2-loss function.</p>
<blockquote>
<p>train -s 0 data_file</p>
</blockquote>
<p>Train a logistic regression model.</p>
<blockquote>
<p>train -v 5 -e 0.001 data_file</p>
</blockquote>
<p>Do five-fold cross-validation using L2-loss SVM.<br />
Use a smaller stopping tolerance 0.001 than the default<br />
0.1 if you want more accurate solutions.</p>
<blockquote>
<p>train -C data_file</p>
</blockquote>
<p>Conduct cross validation many times by L2-loss SVM <br />
and find the parameter C which achieves the best cross <br />
validation accuracy.</p>
<blockquote>
<p>train -C -s 0 -v 3 -c 0.5 -e 0.0001 data_file</p>
</blockquote>
<p>For parameter selection by -C, users can specify other <br />
solvers (currently -s 0 and -s 2 are supported) and <br />
different number of CV folds. Further, users can use <br />
the -c option to specify the smallest C value of the <br />
search range. This setting is useful when users want <br />
to rerun the parameter selection procedure from a <br />
specified C under a different setting, such as a stricter <br />
stopping tolerance -e 0.0001 in the above example.</p>
<blockquote>
<p>train -c 10 -w1 2 -w2 5 -w3 2 four_class_data_file</p>
</blockquote>
<p>Train four classifiers:<br />
positive        negative        Cp      Cn<br />
class 1         class 2,3,4.    20      10<br />
class 2         class 1,3,4.    50      10<br />
class 3         class 1,2,4.    20      10<br />
class 4         class 1,2,3.    10      10</p>
<blockquote>
<p>train -c 10 -w3 1 -w2 5 two_class_data_file</p>
</blockquote>
<p>If there are only two classes, we train ONE model.<br />
The C values for the two classes are 10 and 50.</p>
<blockquote>
<p>predict -b 1 test_file data_file.model output_file</p>
</blockquote>
<p>Output probability estimates (for logistic regression only).</p>
<h1 id="library-usage"><a name="user-content-library-usage" href="#library-usage" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Library Usage</h1>
<ul>
<li>
<p>Function: model<em> train(const struct problem </em>prob,<br />
                const struct parameter *param);</p>
<p>This function constructs and returns a linear classification <br />
or regression model according to the given training data and <br />
parameters.</p>
<p>struct problem describes the problem:</p>
<pre><code>struct problem
{
    int l, n;
    int *y;
    struct feature_node **x;
    double bias;
};
</code></pre>
<p>where <code>l</code> is the number of training data. If bias &gt;= 0, we assume<br />
that one additional feature is added to the end of each data<br />
instance. <code>n</code> is the number of feature (including the bias feature<br />
if bias &gt;= 0). <code>y</code> is an array containing the target values. (integers <br />
in classification, real numbers in regression) And <code>x</code> is an array <br />
of pointers, each of which points to a sparse representation (array <br />
of feature_node) of one training vector.</p>
<p>For example, if we have the following training data:</p>
<p>LABEL       ATTR1   ATTR2   ATTR3   ATTR4   ATTR5<br />
-----       -----   -----   -----   -----   -----<br />
1           0       0.1     0.2     0       0<br />
2           0       0.1     0.3    -1.2     0<br />
1           0.4     0       0       0       0<br />
2           0       0.1     0       1.4     0.5<br />
3          -0.1    -0.2     0.1     1.1     0.1</p>
<p>and bias = 1, then the components of problem are:</p>
<p>l = 5<br />
n = 6</p>
<p>y -&gt; 1 2 1 2 3</p>
<p>x -&gt; [ ] -&gt; (2,0.1) (3,0.2) (6,1) (-1,?)<br />
     [ ] -&gt; (2,0.1) (3,0.3) (4,-1.2) (6,1) (-1,?)<br />
     [ ] -&gt; (1,0.4) (6,1) (-1,?)<br />
     [ ] -&gt; (2,0.1) (4,1.4) (5,0.5) (6,1) (-1,?)<br />
     [ ] -&gt; (1,-0.1) (2,-0.2) (3,0.1) (4,1.1) (5,0.1) (6,1) (-1,?)</p>
<p>struct parameter describes the parameters of a linear classification <br />
or regression model:</p>
<pre><code>struct parameter
{
        int solver_type;

        /* these are for training only */
        double eps;             /* stopping criteria */
        double C;
        int nr_weight;
        int *weight_label;
        double* weight;
        double p;
};
</code></pre>
<p>solver_type can be one of L2R_LR, L2R_L2LOSS_SVC_DUAL, L2R_L2LOSS_SVC, L2R_L1LOSS_SVC_DUAL, MCSVM_CS, L1R_L2LOSS_SVC, L1R_LR, L2R_LR_DUAL, L2R_L2LOSS_SVR, L2R_L2LOSS_SVR_DUAL, L2R_L1LOSS_SVR_DUAL.<br />
  for classification<br />
L2R_LR                L2-regularized logistic regression (primal)<br />
L2R_L2LOSS_SVC_DUAL   L2-regularized L2-loss support vector classification (dual)<br />
L2R_L2LOSS_SVC        L2-regularized L2-loss support vector classification (primal)<br />
L2R_L1LOSS_SVC_DUAL   L2-regularized L1-loss support vector classification (dual)<br />
MCSVM_CS              support vector classification by Crammer and Singer<br />
L1R_L2LOSS_SVC        L1-regularized L2-loss support vector classification<br />
L1R_LR                L1-regularized logistic regression<br />
L2R_LR_DUAL           L2-regularized logistic regression (dual)<br />
  for regression<br />
L2R_L2LOSS_SVR        L2-regularized L2-loss support vector regression (primal)<br />
L2R_L2LOSS_SVR_DUAL   L2-regularized L2-loss support vector regression (dual)<br />
L2R_L1LOSS_SVR_DUAL   L2-regularized L1-loss support vector regression (dual)</p>
<p>C is the cost of constraints violation.<br />
p is the sensitiveness of loss of support vector regression. <br />
eps is the stopping criterion.</p>
<p>nr_weight, weight_label, and weight are used to change the penalty<br />
for some classes (If the weight for a class is not changed, it is<br />
set to 1). This is useful for training classifier using unbalanced<br />
input data or with asymmetric misclassification cost.</p>
<p>nr_weight is the number of elements in the array weight_label and<br />
weight. Each weight[i] corresponds to weight_label[i], meaning that<br />
the penalty of class weight_label[i] is scaled by a factor of weight[i].</p>
<p>If you do not want to change penalty for any of the classes,<br />
just set nr_weight to 0.</p>
<p><em>NOTE</em> To avoid wrong parameters, check_parameter() should be<br />
called before train().</p>
<p>struct model stores the model obtained from the training procedure:</p>
<pre><code>struct model
{
        struct parameter param;
        int nr_class;           /* number of classes */
        int nr_feature;
        double *w;
        int *label;             /* label of each class */
        double bias;
};
</code></pre>
<p>param describes the parameters used to obtain the model.</p>
<p>nr_class and nr_feature are the number of classes and features, <br />
 respectively. nr_class = 2 for regression. </p>
<p>The nr_feature*nr_class array w gives feature weights. We use one<br />
 against the rest for multi-class classification, so each feature<br />
 index corresponds to nr_class weight values. Weights are<br />
 organized in the following way</p>
<p>+------------------+------------------+------------+<br />
 | nr_class weights | nr_class weights |  &hellip;<br />
 | for 1st feature  | for 2nd feature  |<br />
 +------------------+------------------+------------+</p>
<p>If bias &gt;= 0, x becomes [x; bias]. The number of features is<br />
 increased by one, so w is a (nr_feature+1)*nr_class array. The<br />
 value of bias is stored in the variable bias.</p>
<p>The array label stores class labels.</p>
</li>
<li>
<p>Function: void cross_validation(const problem <em>prob, const parameter </em>param, int nr_fold, double *target);</p>
<p>This function conducts cross validation. Data are separated to<br />
nr_fold folds. Under given parameters, sequentially each fold is<br />
validated using the model from training the remaining. Predicted<br />
labels in the validation process are stored in the array called<br />
target.</p>
<p>The format of prob is same as that for train().</p>
</li>
<li>
<p>Function: void find_parameter_C(const struct problem <em>prob, <br />
            const struct parameter </em>param, int nr_fold, double start_C, <br />
        double max_C, double <em>best_C, double </em>best_rate);</p>
<p>This function is similar to cross_validation. However, instead of<br />
conducting cross validation under a specified parameter C, it <br />
conducts cross validation many times under parameters C = start_C, <br />
2<em>start_C, 4</em>start_C, 8*start_C, &hellip;, and finds the best one with<br />
the highest cross validation accuracy.</p>
<p>If start_C &lt;= 0, then this procedure calculates a small enough C <br />
for prob as the start_C. The procedure stops when the models of <br />
all folds become stable or C reaches max_C. The best C and the <br />
corresponding accuracy are assigned to <em>best_C and </em>best_rate,<br />
respectively.</p>
</li>
<li>
<p>Function: double predict(const model <em>model_, const feature_node </em>x);</p>
<p>For a classification model, the predicted class for x is returned.<br />
For a regression model, the function value of x calculated using<br />
the model is returned. </p>
</li>
<li>
<p>Function: double predict_values(const struct model <em>model_,<br />
            const struct feature_node </em>x, double* dec_values);</p>
<p>This function gives nr_w decision values in the array dec_values. <br />
nr_w=1 if regression is applied or the number of classes is two. An exception is<br />
multi-class SVM by Crammer and Singer (-s 4), where nr_w = 2 if there are two classes. For all other situations, nr_w is the <br />
number of classes.</p>
<p>We implement one-vs-the rest multi-class strategy (-s 0,1,2,3,5,6,7) <br />
and multi-class SVM by Crammer and Singer (-s 4) for multi-class SVM.<br />
The class with the highest decision value is returned.</p>
</li>
<li>
<p>Function: double predict_probability(const struct model <em>model_,<br />
            const struct feature_node </em>x, double* prob_estimates);</p>
<p>This function gives nr_class probability estimates in the array<br />
prob_estimates. nr_class can be obtained from the function<br />
get_nr_class. The class with the highest probability is<br />
returned. Currently, we support only the probability outputs of<br />
logistic regression.</p>
</li>
<li>
<p>Function: int get_nr_feature(const model *model_);</p>
<p>The function gives the number of attributes of the model.</p>
</li>
<li>
<p>Function: int get_nr_class(const model *model_);</p>
<p>The function gives the number of classes of the model.<br />
For a regression model, 2 is returned.</p>
</li>
<li>
<p>Function: void get_labels(const model <em>model_, int</em> label);</p>
<p>This function outputs the name of labels into an array called label.<br />
For a regression model, label is unchanged.</p>
</li>
<li>
<p>Function: double get_decfun_coef(const struct model *model_, int feat_idx,<br />
            int label_idx);</p>
<p>This function gives the coefficient for the feature with feature index =<br />
feat_idx and the class with label index = label_idx. Note that feat_idx<br />
starts from 1, while label_idx starts from 0. If feat_idx is not in the<br />
valid range (1 to nr_feature), then a zero value will be returned. For<br />
classification models, if label_idx is not in the valid range (0 to<br />
nr_class-1), then a zero value will be returned; for regression models,<br />
label_idx is ignored.</p>
</li>
<li>
<p>Function: double get_decfun_bias(const struct model *model_, int label_idx);</p>
<p>This function gives the bias term corresponding to the class with the<br />
label_idx. For classification models, if label_idx is not in a valid range<br />
(0 to nr_class-1), then a zero value will be returned; for regression<br />
models, label_idx is ignored.</p>
</li>
<li>
<p>Function: const char <em>check_parameter(const struct problem </em>prob,<br />
            const struct parameter *param);</p>
<p>This function checks whether the parameters are within the feasible<br />
range of the problem. This function should be called before calling<br />
train() and cross_validation(). It returns NULL if the<br />
parameters are feasible, otherwise an error message is returned.</p>
</li>
<li>
<p>Function: int check_probability_model(const struct model *model);</p>
<p>This function returns 1 if the model supports probability output;<br />
otherwise, it returns 0.</p>
</li>
<li>
<p>Function: int check_regression_model(const struct model *model);</p>
<p>This function returns 1 if the model is a regression model; otherwise<br />
it returns 0.</p>
</li>
<li>
<p>Function: int save_model(const char <em>model_file_name,<br />
            const struct model </em>model_);</p>
<p>This function saves a model to a file; returns 0 on success, or -1<br />
if an error occurs.</p>
</li>
<li>
<p>Function: struct model <em>load_model(const char </em>model_file_name);</p>
<p>This function returns a pointer to the model read from the file,<br />
or a null pointer if the model could not be loaded.</p>
</li>
<li>
<p>Function: void free_model_content(struct model *model_ptr);</p>
<p>This function frees the memory used by the entries in a model structure.</p>
</li>
<li>
<p>Function: void free_and_destroy_model(struct model **model_ptr_ptr);</p>
<p>This function frees the memory used by a model and destroys the model<br />
structure.</p>
</li>
<li>
<p>Function: void destroy_param(struct parameter *param);</p>
<p>This function frees the memory used by a parameter set.</p>
</li>
<li>
<p>Function: void set_print_string_function(void (<em>print_func)(const char </em>));</p>
<p>Users can specify their output format by a function. Use<br />
    set_print_string_function(NULL); <br />
for default printing to stdout.</p>
</li>
</ul>
<h1 id="building-windows-binaries"><a name="user-content-building-windows-binaries" href="#building-windows-binaries" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Building Windows Binaries</h1>
<p>Windows binaries are in the directory <code>windows</code>. To build them via<br />
Visual C++, use the following steps:</p>
<ol>
<li>Open a dos command box and change to liblinear directory. If<br />
environment variables of VC++ have not been set, type</li>
</ol>
<p>&ldquo;&rdquo;C:\Program Files (x86)\Microsoft Visual Studio 12.0\VC\bin\amd64\vcvars64.bat&rdquo;&ldquo;</p>
<p>You may have to modify the above command according which version of<br />
VC++ or where it is installed.</p>
<ol>
<li>Type</li>
</ol>
<p>nmake -f Makefile.win clean all</p>
<ol>
<li>(Optional) To build 32-bit windows binaries, you must<br />
    (1) Setup &ldquo;C:\Program Files (x86)\Microsoft Visual Studio 12.0\VC\bin\vcvars32.bat&rdquo; instead of vcvars64.bat<br />
    (2) Change CFLAGS in Makefile.win: /D _WIN64 to /D _WIN32</li>
</ol>
<h1 id="matlaboctave-interface"><a name="user-content-matlaboctave-interface" href="#matlaboctave-interface" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>MATLAB/OCTAVE Interface</h1>
<p>Please check the file README in the directory <code>matlab</code>.</p>
<h1 id="python-interface"><a name="user-content-python-interface" href="#python-interface" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>PYTHON Interface</h1>
<p>Please check the file README in the directory <code>python</code>.</p>
<h1 id="additional-information"><a name="user-content-additional-information" href="#additional-information" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Additional Information</h1>
<p>If you find LIBLINEAR helpful, please cite it as</p>
<p>R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang, and C.-J. Lin.<br />
LIBLINEAR: A Library for Large Linear Classification, Journal of<br />
Machine Learning Research 9(2008), 1871-1874. Software available at<br />
<a href="http://www.csie.ntu.edu.tw/~cjlin/liblinear">http://www.csie.ntu.edu.tw/~cjlin/liblinear</a></p>
<p>For any questions and comments, please send your email to<br />
<a href="mailto:cjlin@csie.ntu.edu.tw">cjlin@csie.ntu.edu.tw</a></p></article></body></html>